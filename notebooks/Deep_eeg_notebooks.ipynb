{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep-eeg-notebooks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kylemath/eeg-notebooks/blob/master/notebooks/Deep_eeg_notebooks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "cH7KRd8ZZPMd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Deep-eeg-notebooks\n",
        "\n",
        "Goal is to make deep learning stacks that processes Muse eeg-notebook EEG trials as input and predicts binary trial category as output. This is all made to run on Google Colab notebooks using cloud GPU capabilities, so the git repo's get loaded at the start of the code into the workspace. Minor mods may be needed to use local Jupyter notebook. Long term goal of command line interface and mne toolbox.\n",
        "\n",
        "Strategy:\n",
        "* Load in Muse data, normal pre-processing to get to trials\n",
        "* Options for frequency or time domain\n",
        "* Decimate time to reduce features\n",
        "* Dataset example: Predict attend left vs attend right on muse cueing data\n",
        "\n",
        "API:\n",
        "* Input the data directory and subject numbers of any eeg-notebook experiment (https://github.com/kylemath/eeg-notebooks)\n",
        "* More general with the master eeg-notebooks - https://github.com/NeuroTechX/eeg-notebooks\n",
        "\n",
        "LearningModels:\n",
        "* First try basic Neural Network (NN)\n",
        "* Then try Convolution Neural Net (CNN)\n",
        "* Then try Long-Short Term Memory Recurrant Neural Net (LSTM, RNN)\n",
        "\n",
        "DataModels:\n",
        "* First pool data over all subjects\n",
        "* Try subject specific models\n",
        "* Then try multilevel models\n",
        "\n",
        "Using: \n",
        "* https://github.com/kylemath/eeg-notebooks\n",
        "* https://github.com/mne-tools/mne-python\n",
        "* https://github.com/keras-team/keras/blob/master/examples/imdb_cnn_lstm.py\n",
        "* https://github.com/ml4a/ml4a-guides/blob/master/notebooks/keras_classification.ipynb\n",
        "* https://github.com/tevisgehr/EEG-Classification\n",
        "\n",
        "Resources:\n",
        "* https://arxiv.org/pdf/1901.05498.pdf \n",
        "* http://proceedings.mlr.press/v56/Thodoroff16.pdf\n",
        "*  https://arxiv.org/abs/1511.06448\n",
        "*  https://github.com/ml4a\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Kf-1ItUyU380",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Setup**"
      ]
    },
    {
      "metadata": {
        "id": "VXe-o8XtG9ki",
        "colab_type": "code",
        "outputId": "727ab558-4538-41e0-8f81-07705d27a4ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install mne\n",
        "from mne import Epochs, find_events, concatenate_raws\n",
        "from mne.time_frequency import tfr_morlet\n",
        "\n",
        "!git clone https://github.com/kylemath/eeg-notebooks.git\n",
        "%cd eeg-notebooks/notebooks\n",
        "from utils import utils\n",
        "\n",
        "import pandas as pd\n",
        "pd.options.display.max_columns = None\n",
        "pd.options.display.precision = 4\n",
        "\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams[\"figure.figsize\"] = (12,12)\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation \n",
        "from keras.layers import Flatten, Conv2D, MaxPooling2D, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#find the factors of a number |to add extra dimension for CNN|\n",
        "def factors(n):\n",
        "      return [i for i in range(1, n + 1) if not n%i]\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mne\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/20/207b7780abf56afb03697c9d358b706ac22d96975c1da755cc9663f358cc/mne-0.17.0.tar.gz (6.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 6.2MB 6.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mne\n",
            "  Running setup.py bdist_wheel for mne ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/59/23/bb/ebafe2eae31064edfb9b384131abd0ec562a9418601cde6d69\n",
            "Successfully built mne\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-0.17.0\n",
            "Cloning into 'eeg-notebooks'...\n",
            "remote: Enumerating objects: 298, done.\u001b[K\n",
            "remote: Counting objects: 100% (298/298), done.\u001b[K\n",
            "remote: Compressing objects: 100% (255/255), done.\u001b[K\n",
            "remote: Total 1764 (delta 142), reused 143 (delta 43), pack-reused 1466\n",
            "Receiving objects: 100% (1764/1764), 108.64 MiB | 18.28 MiB/s, done.\n",
            "Resolving deltas: 100% (765/765), done.\n",
            "Checking out files: 100% (485/485), done.\n",
            "/content/eeg-notebooks/notebooks\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "yR1WkVZKU2Vm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Parameters**"
      ]
    },
    {
      "metadata": {
        "id": "QGVIiUbAU1nA",
        "colab_type": "code",
        "outputId": "fcd7660b-d8b1-4a99-be33-ef86638440bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "#Parameters#\n",
        "#subject folders in data folder\n",
        "subs = [101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112,\n",
        "        202, 203, 204, 205, 207, 208, 209, 210, 211, \n",
        "        301, 302, 303, 304, 305, 306, 307, 308, 309]\n",
        "\n",
        "data_dir = 'visual/cueing'\n",
        "event_ids = ['LeftCue','RightCue']\n",
        "nsesh = 2\n",
        "\n",
        "#for testing\n",
        "#subs = [ 205, 207, 208, 209]\n",
        "subs = [2]\n",
        "nsesh = 1\n",
        "#number of sessions in each subject folder\n",
        "\n",
        "## Can load other experiments like this - NN and CNN model works great\n",
        "#subs = [ 1]\n",
        "#nsesh = 1\n",
        "#data_dir = 'visual/P300'\n",
        "#event_ids = ['Standard','Target']\n",
        "##\n",
        "\n",
        "## Can load other experiments like this - NN and CNN model works best here\n",
        "#subs = [ 4]\n",
        "#nsesh = 1\n",
        "#data_dir = 'visual/SSVEP'\n",
        "#event_ids = ['30Hz','20Hz']\n",
        "##\n",
        "\n",
        "\n",
        "load_verbose = 0 #print output during loading\n",
        "\n",
        "sfreq=256.\n",
        "decim=2  # to decrease number of time features \n",
        "nsfreq = sfreq/decim\n",
        "\n",
        "#filter\n",
        "eeg_filter_highpass = 1\n",
        "eeg_filter_lowpass = nsfreq/2.5  #lower to avoid aliasing from decim\n",
        "\n",
        "#artifact rejection\n",
        "rej_thresh_uV = 10000 #300 removes most blinks, 1000 keeps most trials\n",
        "rej_thresh = rej_thresh_uV*1e-6\n",
        "\n",
        "#trial epoch limits \n",
        "tmin=-1 #-1\n",
        "tmax=4 #2\n",
        "baseline=(-1, 0) #None or (start, end) in seconds\n",
        "#gets removed from training data but used during processing\n",
        "\n",
        "#wavelet settings\n",
        "f_low = 2\n",
        "f_high = 40\n",
        "f_bins = 100  # to decrease number of frequency features\n",
        "wave_cycles = 6 # cycles of each frequency to convolve with data\n",
        "spect_baseline = [-1,-.5] #gets removed from training data but used during processing\n",
        "electrodes_out = [0,1,2,3]  # to decrease number of electrode features from [0,1,2,3] or [0,1,2,3,4] with aux electrode (untested)\n",
        "frequencies =  np.linspace(f_low, f_high, f_bins, endpoint=True)\n",
        "\n",
        "frequency_domain = 1  #if True uses wavelets otherwise use time series\n",
        "\n",
        "#Training Settings\n",
        "batch_size = 1\n",
        "train_epochs = 500\n",
        "num_classes = len(event_ids)\n",
        "test_split = 0.2\n",
        "val_split = 0.2\n",
        "random_seed = 1017\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# 'CNN','LSTM','NN'\n",
        "model_type = 'NN'\n",
        "\n",
        "print('Parameters Set')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters Set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g2a98-rwL9wl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Preprocessing of EEG Data**\n",
        "\n",
        "* LoadData - Each data file is from one session of one subject of the muse cueing task from eeg-notebooks from psych 375 A1 dataset\n",
        "* Filtering - Most ERP components are composed of lower frequency fluctuations in the EEG signal. Thus, we can filter out all frequencies between 1 and 30 hz in order to increase our ability to detect them.\n",
        "* Epoching - Next, we will chunk (epoch) the data into segments representing the data 1000ms before to 2000ms after each cue, we will reject every epoch where the amplitude of the signal exceeded 100 uV, which should most eye blinks."
      ]
    },
    {
      "metadata": {
        "id": "6A3mgX7ILZFK",
        "colab_type": "code",
        "outputId": "9bde8b8b-c6eb-47b3-ab45-d253b9ed0d2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "cell_type": "code",
      "source": [
        "#Load Data\n",
        "print('Loading Data')\n",
        "isub = subs[0]\n",
        "print(isub)\n",
        "raw = utils.load_data(data_dir, sfreq=sfreq ,subject_nb=isub, session_nb=1,verbose=load_verbose)\n",
        "if nsesh == 2:\n",
        "  raw.append(utils.load_data(data_dir, sfreq=sfreq,subject_nb=isub, session_nb=2,verbose=load_verbose))\n",
        "\n",
        "if len(subs)>1:\n",
        "  for isub in subs[1:]:\n",
        "    print(isub)\n",
        "    raw.append(utils.load_data(data_dir, sfreq=sfreq,subject_nb=isub, session_nb=1,verbose=load_verbose))\n",
        "    if nsesh == 2:\n",
        "      raw.append(utils.load_data(data_dir, sfreq=sfreq,subject_nb=isub, session_nb=2,verbose=load_verbose))\n",
        "  \n",
        "#Filtering\n",
        "print('Filtering Data')\n",
        "raw.filter(eeg_filter_highpass,eeg_filter_lowpass, method='iir', verbose='WARNING' )\n",
        "\n",
        "#Plot filtred data spectra if desired\n",
        "#raw.plot_psd(fmin=eeg_filter_highpass, fmax=eeg_filter_lowpass ) \n",
        "\n",
        "#Epoching\n",
        "event_id = {event_ids[0]: 1, event_ids[1]: 2}\n",
        "events = find_events(raw)\n",
        "epochs = Epochs(raw, events=events, event_id=event_id, \n",
        "                tmin=tmin, tmax=tmax, baseline=baseline, \n",
        "                preload=True,reject={'eeg':rej_thresh},\n",
        "                verbose=False, decim=decim)\n",
        "\n",
        "print('sample drop %: ', (1 - len(epochs.events)/len(events)) * 100)\n",
        "%matplotlib inline\n",
        "conditions = OrderedDict()\n",
        "conditions[event_ids[0]] = [1]\n",
        "conditions[event_ids[1]] = [2]\n",
        "\n",
        "#plot ERPs if desired\n",
        "#fig, ax = utils.plot_conditions(epochs, conditions=conditions, ylim=(-20,20) )"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Data\n",
            "2\n",
            "Filtering Data\n",
            "342 events found\n",
            "Event IDs: [ 1  2 11 12 21 22]\n",
            "sample drop %:  50.877192982456144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EmvSu1bOZiO0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Spectrogram **\n",
        "\n",
        "* All electrodes are considered on each trial\n",
        "* Many frequencies are used in the wavelet analysis while the output of the morlet is decimated in time.\n",
        "* Two conditions are done separate and concatenated\n",
        "* X is a trials x freq x time matrix\n",
        "* Y is a trials array of condition labels (turned into one hot vectors later in code)\n"
      ]
    },
    {
      "metadata": {
        "id": "Xs-_8GRYZar7",
        "colab_type": "code",
        "outputId": "e446727c-5cbd-4062-e10b-64120ec72f64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "cell_type": "code",
      "source": [
        "if frequency_domain:\n",
        "  # Condition0\n",
        "  print('Computing Morlet Wavelets on ' + event_ids[0])\n",
        "\n",
        "  tfr0 = tfr_morlet(epochs[event_ids[0]], freqs=frequencies, \n",
        "                        n_cycles=wave_cycles, return_itc=False,\n",
        "                        picks=electrodes_out,average=False,decim=decim)\n",
        "  tfr0 = tfr0.apply_baseline(spect_baseline,mode='mean')\n",
        "  stim_onset = np.argmax(tfr0.times>0)\n",
        "  new_times = tfr0.times[stim_onset:]\n",
        "\n",
        "  #reshape data\n",
        "  cond0_power_out = np.moveaxis(tfr0.data[:,:,:,stim_onset:],1,3) #move electrodes last\n",
        "  cond0_power_out = np.moveaxis(cond0_power_out,1,2) # move time second\n",
        "  #cond0_power_out[:,0:5,0:5,:] = 0 #for testing model add mark to image\n",
        "\n",
        "  print('Condition zero trials: ' + str(len(cond0_power_out)))\n",
        "\n",
        "  print(event_ids[0] + ' Time Points: ' + str(len(new_times)))\n",
        "  print(event_ids[0] + ' Frequencies: ' + str(len(tfr0.freqs)))\n",
        "\n",
        "  #Condition1\n",
        "  print('Computing Morlet Wavelets on ' + event_ids[1])\n",
        "  tfr1 = tfr_morlet(epochs[event_ids[1]], freqs=frequencies, \n",
        "                        n_cycles=wave_cycles, return_itc=False,\n",
        "                        picks=electrodes_out,average=False,decim=decim)\n",
        "  tfr1 = tfr1.apply_baseline(spect_baseline,mode='mean')\n",
        "  \n",
        "  #reshape data\n",
        "  cond1_power_out = np.moveaxis(tfr1.data[:,:,:,stim_onset:],1,3)\n",
        "  cond1_power_out = np.moveaxis(cond1_power_out,1,2) # move time second\n",
        "  #cond1_power_out[:,0:5,0:5,:] = 1 #for testing model add mark to image\n",
        "\n",
        "  print('Condition one trials: ' + str(len(cond1_power_out)))    \n",
        "\n",
        "  print(event_ids[1] + ' Time Points: ' + str(len(new_times)))\n",
        "  print(event_ids[1] + ' Frequencies: ' + str(len(tfr1.freqs)))\n",
        "  X = np.append(cond0_power_out,cond1_power_out,0);\n",
        "  \n",
        "  if model_type != 'CNN':\n",
        "    #reshape to trials x times x variables for LSTM and NN model\n",
        "    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2] * X.shape[3]),order='F')\n",
        "   \n",
        "  #Normalize X - need to save mean and std for future test + val\n",
        "  X = (X - np.mean(X)) / np.std(X)\n",
        "  \n",
        "  #Append Data\n",
        "  Y_class = np.append(np.zeros(len(cond0_power_out)), np.ones(len(cond1_power_out)),0)\n",
        "  \n",
        "  print('Combined X Shape: ' + str(X.shape))\n",
        "  print('Combined Y Shape: ' + str(Y_class.shape))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing Morlet Wavelets on LeftCue\n",
            "Applying baseline correction (mode: mean)\n",
            "Condition zero trials: 86\n",
            "LeftCue Time Points: 256\n",
            "LeftCue Frequencies: 100\n",
            "Computing Morlet Wavelets on RightCue\n",
            "Applying baseline correction (mode: mean)\n",
            "Condition one trials: 82\n",
            "RightCue Time Points: 256\n",
            "RightCue Frequencies: 100\n",
            "Combined X Shape: (168, 256, 400)\n",
            "Combined Y Shape: (168,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_d74N_oqMlGF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Time Domain**\n",
        "\n",
        "* Instead may want to retain time domain data\n",
        "* After Epoching, arange data into useful format with labels"
      ]
    },
    {
      "metadata": {
        "id": "qoBQKZ2uMOpL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not frequency_domain:\n",
        "  \n",
        "  #epochs = epochs.decimate(10) #probably don't do this\n",
        "  X = np.moveaxis(epochs._data,1,2); #but channels last\n",
        "  \n",
        "  #take post baseline only\n",
        "  stim_onset = np.argmax(epochs.times>0)\n",
        "  new_times = epochs.times[stim_onset:]\n",
        "  X = X[:,stim_onset:,:]\n",
        "  \n",
        "  print(X.shape)\n",
        "  if model_type == 'CNN' and not frequency_domain:\n",
        "    # reshape for CNN 512 ms long, factors 64 * 8\n",
        "    # these 10's need to be found algorithmically (find any factor of the number)\n",
        "    all_factors = factors(X.shape[1])\n",
        "    X = np.reshape(X, (X.shape[0], int(X.shape[1]/all_factors[3]), all_factors[3], X.shape[2]),order='F')\n",
        "  \n",
        "  #Normalize X - need to save mean and std for future test + val\n",
        "  X = (X - np.mean(X)) / np.std(X)\n",
        "  \n",
        "  Y_class = epochs.events[:,2]-1  #subtract 1 to make 0 and 1\n",
        "  \n",
        "  print('X Shape: ' + str(X.shape))\n",
        "  print('Y Shape: ' + str(Y_class.shape))\n",
        "  print('Y Example: ' + str(Y_class[0:10]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WqVTXiwrZxbf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Prepare Data for Model**\n"
      ]
    },
    {
      "metadata": {
        "id": "4xyrsW2kZW8D",
        "colab_type": "code",
        "outputId": "4ce15c76-c761-403d-c3f0-185f8045a3bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "cell_type": "code",
      "source": [
        "# convert class vectors to one hot Y and recast X\n",
        "Y = keras.utils.to_categorical(Y_class, num_classes)\n",
        "X = X.astype('float32')\n",
        "\n",
        "# Split training test and validation data \n",
        "val_prop = val_split / (1-test_split)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=test_split,random_state=random_seed) \n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=val_prop, random_state=random_seed)\n",
        "\n",
        "# Compute model input shape\n",
        "input_shape = X.shape[1:]\n",
        "\n",
        "\n",
        "print('X Range: ' + str(np.min(X)) + ':' + str(np.max(X)))\n",
        "print('X Examples:')\n",
        "\n",
        "#for plotting\n",
        "\n",
        "vmin = (np.std(X)/4) * -1\n",
        "vmax = np.std(X)/4  \n",
        "\n",
        "#Plot Example Data\n",
        "#f, axarr = plt.subplots(2,2, figsize = (8,8))\n",
        "#axarr[0][0].set_title(event_ids[0])\n",
        "#axarr[0][0].imshow(X[0],vmin=vmin, vmax=vmax, aspect='auto')\n",
        "\n",
        "#axarr[0][0].invert_yaxis()\n",
        "#axarr[1][0].imshow(X[1],vmin=vmin, vmax=vmax, aspect='auto')\n",
        "#axarr[1][0].invert_yaxis()\n",
        "\n",
        "#axarr[0][1].set_title(event_ids[1])\n",
        "#axarr[0][1].imshow(X[-1],vmin=vmin, vmax=vmax, aspect='auto')\n",
        "#axarr[0][1].invert_yaxis()\n",
        "#axarr[1][1].imshow(X[-2],vmin=vmin, vmax=vmax, aspect='auto')\n",
        "#axarr[1][1].invert_yaxis()\n",
        "#;\n",
        "\n",
        "print('Input Shape: ' + str(input_shape))\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print(x_val.shape[0], 'validation samples')\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Range: -48.53979:40.14357\n",
            "X Examples:\n",
            "Input Shape: (256, 400)\n",
            "x_train shape: (100, 256, 400)\n",
            "100 train samples\n",
            "34 test samples\n",
            "34 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mKzYDoF1TQmK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Build Model and Train**"
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "JxjbgyC5G7AZ",
        "colab_type": "code",
        "outputId": "f2b479eb-416d-4684-d9e3-f7e495824a30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17571
        }
      },
      "cell_type": "code",
      "source": [
        "print('Running ' +  model_type + ' Model:')\n",
        "if model_type == 'LSTM':\n",
        "  ##---LSTM - Many to two, sequence of time to classes\n",
        "  units = [input_shape[1], 4, 4, num_classes]\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(input_shape=(None, units[0]) ,units=units[1], return_sequences=True))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(LSTM(units=units[2],return_sequences=False))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(units=units[3]))\n",
        "  model.add(Activation(\"softmax\"))\n",
        "\n",
        "if model_type == 'NN':\n",
        "  ##---DenseFeedforward Network\n",
        "  model = Sequential()\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dropout(.20))\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dropout(.20))\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dropout(.20))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "if model_type == 'CNN':\n",
        "  ##----Convolutional Network\n",
        "  # parameters above need to be adjusted until input shape is square on \n",
        "  # dimensions 1 and 2 (like an image) and electrodes on third\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(49, (3, 3), input_shape=input_shape))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(32, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(10))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "# initiate adam optimizer\n",
        "opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, \n",
        "                            epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Train Model\n",
        "history = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=train_epochs,\n",
        "          validation_data=(x_val, y_val),\n",
        "          shuffle=True,\n",
        "          verbose=True)\n",
        "         \n",
        "#Summarize\n",
        "model.summary()\n",
        " \n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.semilogy(history.history['loss'])\n",
        "plt.semilogy(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Test on left out Test data\n",
        "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running NN Model:\n",
            "Train on 100 samples, validate on 34 samples\n",
            "Epoch 1/500\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 2.7622 - acc: 0.5600 - val_loss: 3.7831 - val_acc: 0.5588\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.8390 - acc: 0.5100 - val_loss: 2.0487 - val_acc: 0.4706\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.8424 - acc: 0.4800 - val_loss: 2.3207 - val_acc: 0.5294\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.4005 - acc: 0.4800 - val_loss: 3.7015 - val_acc: 0.3529\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.9002 - acc: 0.4400 - val_loss: 2.9316 - val_acc: 0.4706\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0237 - acc: 0.5400 - val_loss: 2.7982 - val_acc: 0.4706\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.1497 - acc: 0.5200 - val_loss: 3.8825 - val_acc: 0.3824\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.4725 - acc: 0.5000 - val_loss: 2.8107 - val_acc: 0.4412\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9202 - acc: 0.6000 - val_loss: 2.4646 - val_acc: 0.4706\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.9214 - acc: 0.5000 - val_loss: 3.5416 - val_acc: 0.4706\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.2980 - acc: 0.5300 - val_loss: 2.5961 - val_acc: 0.5000\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.6308 - acc: 0.5100 - val_loss: 3.5285 - val_acc: 0.3824\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.2117 - acc: 0.5000 - val_loss: 3.4818 - val_acc: 0.3824\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9936 - acc: 0.5900 - val_loss: 3.4392 - val_acc: 0.4118\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.3460 - acc: 0.5300 - val_loss: 3.8164 - val_acc: 0.3824\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.5835 - acc: 0.5400 - val_loss: 3.5134 - val_acc: 0.4118\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0226 - acc: 0.5700 - val_loss: 3.5527 - val_acc: 0.4412\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.6874 - acc: 0.5400 - val_loss: 3.5852 - val_acc: 0.5000\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.3514 - acc: 0.6400 - val_loss: 3.5828 - val_acc: 0.4412\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.3995 - acc: 0.5900 - val_loss: 3.6954 - val_acc: 0.4412\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.4532 - acc: 0.5200 - val_loss: 3.2229 - val_acc: 0.4412\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.6145 - acc: 0.5500 - val_loss: 3.2456 - val_acc: 0.4412\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.8435 - acc: 0.5200 - val_loss: 3.5819 - val_acc: 0.4412\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.3415 - acc: 0.5300 - val_loss: 3.4187 - val_acc: 0.4412\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.5458 - acc: 0.4900 - val_loss: 3.5034 - val_acc: 0.4412\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.2536 - acc: 0.5100 - val_loss: 3.5253 - val_acc: 0.4412\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.7932 - acc: 0.5200 - val_loss: 3.6267 - val_acc: 0.4118\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.7985 - acc: 0.5100 - val_loss: 3.6989 - val_acc: 0.4118\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8078 - acc: 0.5800 - val_loss: 3.6581 - val_acc: 0.4118\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.8158 - acc: 0.5300 - val_loss: 3.6227 - val_acc: 0.4118\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.9978 - acc: 0.5000 - val_loss: 3.4954 - val_acc: 0.4412\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.3566 - acc: 0.5500 - val_loss: 3.1191 - val_acc: 0.4118\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.7930 - acc: 0.5000 - val_loss: 3.0976 - val_acc: 0.4118\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 3.0127 - acc: 0.4900 - val_loss: 2.8981 - val_acc: 0.3824\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0345 - acc: 0.5500 - val_loss: 2.8695 - val_acc: 0.4706\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8551 - acc: 0.5600 - val_loss: 2.9833 - val_acc: 0.4412\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6830 - acc: 0.5700 - val_loss: 2.9853 - val_acc: 0.4412\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1072 - acc: 0.5700 - val_loss: 2.8031 - val_acc: 0.4118\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7248 - acc: 0.5700 - val_loss: 3.4684 - val_acc: 0.3824\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9524 - acc: 0.5500 - val_loss: 3.1102 - val_acc: 0.4412\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5638 - acc: 0.6100 - val_loss: 3.0350 - val_acc: 0.4412\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0579 - acc: 0.5800 - val_loss: 3.5468 - val_acc: 0.4118\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0149 - acc: 0.5500 - val_loss: 2.7506 - val_acc: 0.4706\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6939 - acc: 0.5600 - val_loss: 2.9430 - val_acc: 0.4412\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7533 - acc: 0.5600 - val_loss: 2.9276 - val_acc: 0.4412\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9899 - acc: 0.5800 - val_loss: 2.9395 - val_acc: 0.4412\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1580 - acc: 0.5600 - val_loss: 3.0755 - val_acc: 0.4412\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6348 - acc: 0.5700 - val_loss: 3.1212 - val_acc: 0.4706\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8038 - acc: 0.5600 - val_loss: 3.0159 - val_acc: 0.4412\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8420 - acc: 0.5900 - val_loss: 3.1064 - val_acc: 0.4412\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9641 - acc: 0.5500 - val_loss: 3.3289 - val_acc: 0.4412\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.3131 - acc: 0.5900 - val_loss: 3.1830 - val_acc: 0.4412\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6337 - acc: 0.6000 - val_loss: 3.1870 - val_acc: 0.4412\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5221 - acc: 0.5800 - val_loss: 3.1821 - val_acc: 0.4412\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.4846 - acc: 0.6100 - val_loss: 3.2236 - val_acc: 0.4412\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.3847 - acc: 0.5900 - val_loss: 3.1560 - val_acc: 0.4412\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0259 - acc: 0.5500 - val_loss: 3.0768 - val_acc: 0.4412\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8029 - acc: 0.5800 - val_loss: 2.9909 - val_acc: 0.4412\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9168 - acc: 0.5700 - val_loss: 2.8258 - val_acc: 0.4412\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7053 - acc: 0.5400 - val_loss: 2.6202 - val_acc: 0.4706\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5314 - acc: 0.5600 - val_loss: 2.6190 - val_acc: 0.4706\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.1967 - acc: 0.5200 - val_loss: 2.7105 - val_acc: 0.4706\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6713 - acc: 0.5600 - val_loss: 2.5410 - val_acc: 0.4706\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6770 - acc: 0.5500 - val_loss: 2.5842 - val_acc: 0.4706\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9466 - acc: 0.5500 - val_loss: 2.6599 - val_acc: 0.4706\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.9090 - acc: 0.5400 - val_loss: 2.5318 - val_acc: 0.4706\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9821 - acc: 0.5500 - val_loss: 2.5549 - val_acc: 0.4706\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6025 - acc: 0.5500 - val_loss: 2.6525 - val_acc: 0.4706\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.8342 - acc: 0.5600 - val_loss: 2.5556 - val_acc: 0.4706\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.4643 - acc: 0.5500 - val_loss: 2.5411 - val_acc: 0.4706\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.5033 - acc: 0.5800 - val_loss: 2.6201 - val_acc: 0.4706\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.3004 - acc: 0.5200 - val_loss: 2.6358 - val_acc: 0.4706\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6552 - acc: 0.5600 - val_loss: 2.6836 - val_acc: 0.4706\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6801 - acc: 0.5600 - val_loss: 2.6482 - val_acc: 0.4706\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5176 - acc: 0.5500 - val_loss: 2.6194 - val_acc: 0.4706\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5377 - acc: 0.5500 - val_loss: 2.6310 - val_acc: 0.4706\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6647 - acc: 0.5400 - val_loss: 2.6868 - val_acc: 0.4706\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.2875 - acc: 0.5800 - val_loss: 2.1861 - val_acc: 0.5000\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.7478 - acc: 0.5500 - val_loss: 2.6796 - val_acc: 0.4706\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9636 - acc: 0.5300 - val_loss: 2.2610 - val_acc: 0.5000\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.3309 - acc: 0.5800 - val_loss: 2.2820 - val_acc: 0.5000\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.4858 - acc: 0.5700 - val_loss: 2.2121 - val_acc: 0.5000\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6289 - acc: 0.5600 - val_loss: 2.4144 - val_acc: 0.5000\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5039 - acc: 0.5600 - val_loss: 2.2496 - val_acc: 0.5000\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.4736 - acc: 0.5600 - val_loss: 2.4819 - val_acc: 0.5000\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6242 - acc: 0.5600 - val_loss: 2.3916 - val_acc: 0.5000\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.3502 - acc: 0.5700 - val_loss: 2.3630 - val_acc: 0.5000\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.3605 - acc: 0.5700 - val_loss: 2.3442 - val_acc: 0.5000\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.1990 - acc: 0.5600 - val_loss: 2.3994 - val_acc: 0.5000\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.4547 - acc: 0.5300 - val_loss: 2.1407 - val_acc: 0.4706\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5783 - acc: 0.5600 - val_loss: 2.3641 - val_acc: 0.4706\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5394 - acc: 0.5500 - val_loss: 2.4075 - val_acc: 0.4706\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.3275 - acc: 0.5800 - val_loss: 2.4601 - val_acc: 0.4706\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.1910 - acc: 0.5200 - val_loss: 2.4963 - val_acc: 0.4412\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.4813 - acc: 0.5900 - val_loss: 2.2522 - val_acc: 0.5588\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.3262 - acc: 0.6100 - val_loss: 2.3857 - val_acc: 0.5000\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.1748 - acc: 0.6200 - val_loss: 2.3962 - val_acc: 0.5000\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5087 - acc: 0.5400 - val_loss: 2.3446 - val_acc: 0.5294\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.3046 - acc: 0.6000 - val_loss: 2.4506 - val_acc: 0.4706\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.3199 - acc: 0.5900 - val_loss: 2.4913 - val_acc: 0.5588\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.3558 - acc: 0.6000 - val_loss: 2.6860 - val_acc: 0.4706\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.3613 - acc: 0.5900 - val_loss: 2.1313 - val_acc: 0.5294\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.6566 - acc: 0.5800 - val_loss: 2.3086 - val_acc: 0.5000\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.1747 - acc: 0.6200 - val_loss: 2.3568 - val_acc: 0.4706\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5385 - acc: 0.6000 - val_loss: 2.6145 - val_acc: 0.4706\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.3563 - acc: 0.5900 - val_loss: 2.3289 - val_acc: 0.5294\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.1417 - acc: 0.6500 - val_loss: 2.5356 - val_acc: 0.4706\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.4678 - acc: 0.6100 - val_loss: 2.6478 - val_acc: 0.4706\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.2046 - acc: 0.6300 - val_loss: 3.1671 - val_acc: 0.4118\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.3014 - acc: 0.6100 - val_loss: 3.1448 - val_acc: 0.4118\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7955 - acc: 0.6100 - val_loss: 2.4965 - val_acc: 0.3529\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.8844 - acc: 0.6400 - val_loss: 2.2932 - val_acc: 0.4412\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6939 - acc: 0.6500 - val_loss: 2.3751 - val_acc: 0.3529\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7164 - acc: 0.6600 - val_loss: 2.4593 - val_acc: 0.3529\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9952 - acc: 0.6400 - val_loss: 1.5138 - val_acc: 0.4118\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7851 - acc: 0.6200 - val_loss: 1.8754 - val_acc: 0.4118\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7310 - acc: 0.7000 - val_loss: 2.3347 - val_acc: 0.4706\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.8051 - acc: 0.6200 - val_loss: 1.3393 - val_acc: 0.5000\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7058 - acc: 0.6700 - val_loss: 1.6951 - val_acc: 0.4412\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6862 - acc: 0.6900 - val_loss: 1.5974 - val_acc: 0.4706\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6971 - acc: 0.6600 - val_loss: 1.7278 - val_acc: 0.4412\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.4555 - acc: 0.6600 - val_loss: 3.9383 - val_acc: 0.4412\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.0091 - acc: 0.6400 - val_loss: 2.9945 - val_acc: 0.4706\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6890 - acc: 0.7100 - val_loss: 2.0042 - val_acc: 0.4412\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.8533 - acc: 0.6500 - val_loss: 1.9642 - val_acc: 0.4118\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6837 - acc: 0.6900 - val_loss: 2.0752 - val_acc: 0.4412\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7255 - acc: 0.6700 - val_loss: 2.0674 - val_acc: 0.4118\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9725 - acc: 0.6600 - val_loss: 3.7662 - val_acc: 0.4412\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.5042 - acc: 0.7000 - val_loss: 3.8829 - val_acc: 0.4706\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.3194 - acc: 0.6700 - val_loss: 3.6883 - val_acc: 0.4706\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.3661 - acc: 0.6700 - val_loss: 3.5520 - val_acc: 0.4706\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.0136 - acc: 0.6300 - val_loss: 3.6377 - val_acc: 0.5000\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.2065 - acc: 0.6500 - val_loss: 3.1012 - val_acc: 0.4706\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.1516 - acc: 0.6700 - val_loss: 2.9010 - val_acc: 0.5000\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.2680 - acc: 0.6800 - val_loss: 2.4644 - val_acc: 0.5000\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.4856 - acc: 0.6600 - val_loss: 2.3854 - val_acc: 0.5000\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.2709 - acc: 0.7000 - val_loss: 2.3331 - val_acc: 0.5000\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.4647 - acc: 0.6500 - val_loss: 1.9451 - val_acc: 0.5000\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.1037 - acc: 0.6800 - val_loss: 1.9432 - val_acc: 0.5000\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7875 - acc: 0.6900 - val_loss: 1.9613 - val_acc: 0.5000\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9239 - acc: 0.6900 - val_loss: 2.0235 - val_acc: 0.5000\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7980 - acc: 0.6800 - val_loss: 1.6382 - val_acc: 0.5000\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6421 - acc: 0.7000 - val_loss: 1.7302 - val_acc: 0.5000\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6865 - acc: 0.7000 - val_loss: 1.8178 - val_acc: 0.5000\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6826 - acc: 0.6600 - val_loss: 1.7855 - val_acc: 0.5000\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6060 - acc: 0.7300 - val_loss: 1.9227 - val_acc: 0.5000\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6348 - acc: 0.7100 - val_loss: 1.6495 - val_acc: 0.5588\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7367 - acc: 0.6600 - val_loss: 1.6686 - val_acc: 0.5000\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.8313 - acc: 0.6900 - val_loss: 1.5503 - val_acc: 0.5000\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6454 - acc: 0.7200 - val_loss: 1.7277 - val_acc: 0.5000\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6313 - acc: 0.7200 - val_loss: 1.6762 - val_acc: 0.5000\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6574 - acc: 0.7300 - val_loss: 1.7145 - val_acc: 0.4706\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6447 - acc: 0.7200 - val_loss: 1.7449 - val_acc: 0.4706\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9217 - acc: 0.7300 - val_loss: 1.7266 - val_acc: 0.4706\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7707 - acc: 0.7400 - val_loss: 1.8575 - val_acc: 0.5000\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6109 - acc: 0.7300 - val_loss: 1.7585 - val_acc: 0.5000\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6687 - acc: 0.6800 - val_loss: 1.7392 - val_acc: 0.5000\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6495 - acc: 0.6900 - val_loss: 1.5573 - val_acc: 0.5000\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6252 - acc: 0.7300 - val_loss: 3.0659 - val_acc: 0.4706\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.1518 - acc: 0.7200 - val_loss: 2.9437 - val_acc: 0.5000\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7564 - acc: 0.7100 - val_loss: 3.0688 - val_acc: 0.4706\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6312 - acc: 0.7400 - val_loss: 3.0656 - val_acc: 0.4706\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9171 - acc: 0.7200 - val_loss: 2.5194 - val_acc: 0.4706\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4769 - acc: 0.7000 - val_loss: 2.4469 - val_acc: 0.5000\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.8178 - acc: 0.7100 - val_loss: 2.3784 - val_acc: 0.4706\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7887 - acc: 0.7500 - val_loss: 2.7219 - val_acc: 0.5000\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7293 - acc: 0.7600 - val_loss: 3.0347 - val_acc: 0.5000\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.8605 - acc: 0.7100 - val_loss: 2.8221 - val_acc: 0.5000\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9158 - acc: 0.7000 - val_loss: 2.7537 - val_acc: 0.4412\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6094 - acc: 0.7500 - val_loss: 2.7210 - val_acc: 0.4706\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6443 - acc: 0.7000 - val_loss: 2.8361 - val_acc: 0.5000\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6721 - acc: 0.6900 - val_loss: 2.7755 - val_acc: 0.4118\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6373 - acc: 0.7000 - val_loss: 2.5701 - val_acc: 0.4706\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7574 - acc: 0.7500 - val_loss: 2.5763 - val_acc: 0.4706\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7957 - acc: 0.7200 - val_loss: 3.0420 - val_acc: 0.5294\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6065 - acc: 0.7500 - val_loss: 2.9253 - val_acc: 0.5000\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6351 - acc: 0.7200 - val_loss: 2.5828 - val_acc: 0.5294\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7417 - acc: 0.7700 - val_loss: 2.9963 - val_acc: 0.4706\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6423 - acc: 0.7000 - val_loss: 2.9902 - val_acc: 0.4706\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6000 - acc: 0.7500 - val_loss: 2.8642 - val_acc: 0.5000\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6436 - acc: 0.7500 - val_loss: 2.5754 - val_acc: 0.4706\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4707 - acc: 0.7300 - val_loss: 2.6238 - val_acc: 0.4706\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7392 - acc: 0.7000 - val_loss: 2.5549 - val_acc: 0.5000\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7389 - acc: 0.7000 - val_loss: 2.0260 - val_acc: 0.4412\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5954 - acc: 0.7700 - val_loss: 2.1523 - val_acc: 0.5000\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6199 - acc: 0.7500 - val_loss: 2.0538 - val_acc: 0.4706\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7551 - acc: 0.7500 - val_loss: 2.2253 - val_acc: 0.5000\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6491 - acc: 0.7100 - val_loss: 2.2661 - val_acc: 0.5000\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6395 - acc: 0.7200 - val_loss: 2.0868 - val_acc: 0.5000\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6521 - acc: 0.7100 - val_loss: 2.2771 - val_acc: 0.4412\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6326 - acc: 0.7300 - val_loss: 2.2929 - val_acc: 0.4412\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6426 - acc: 0.7300 - val_loss: 2.3782 - val_acc: 0.4706\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6476 - acc: 0.7000 - val_loss: 1.6778 - val_acc: 0.5294\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6091 - acc: 0.7600 - val_loss: 2.2559 - val_acc: 0.4706\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.8855 - acc: 0.7800 - val_loss: 2.1629 - val_acc: 0.5000\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6424 - acc: 0.7200 - val_loss: 2.5086 - val_acc: 0.5000\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6065 - acc: 0.7500 - val_loss: 2.3160 - val_acc: 0.4706\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5853 - acc: 0.7700 - val_loss: 2.4837 - val_acc: 0.5000\n",
            "Epoch 199/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5976 - acc: 0.7700 - val_loss: 2.5590 - val_acc: 0.5000\n",
            "Epoch 200/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6446 - acc: 0.7100 - val_loss: 2.1827 - val_acc: 0.5000\n",
            "Epoch 201/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4683 - acc: 0.7400 - val_loss: 2.3324 - val_acc: 0.5000\n",
            "Epoch 202/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6055 - acc: 0.7500 - val_loss: 2.6126 - val_acc: 0.5000\n",
            "Epoch 203/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7685 - acc: 0.7400 - val_loss: 2.3405 - val_acc: 0.5000\n",
            "Epoch 204/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5948 - acc: 0.7700 - val_loss: 2.5777 - val_acc: 0.4706\n",
            "Epoch 205/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9334 - acc: 0.7300 - val_loss: 2.7469 - val_acc: 0.5000\n",
            "Epoch 206/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5930 - acc: 0.7600 - val_loss: 2.6341 - val_acc: 0.4706\n",
            "Epoch 207/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6138 - acc: 0.7500 - val_loss: 2.3945 - val_acc: 0.5000\n",
            "Epoch 208/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6152 - acc: 0.7400 - val_loss: 2.7098 - val_acc: 0.4412\n",
            "Epoch 209/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6279 - acc: 0.7300 - val_loss: 2.6038 - val_acc: 0.4412\n",
            "Epoch 210/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5973 - acc: 0.7600 - val_loss: 2.8013 - val_acc: 0.4706\n",
            "Epoch 211/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7393 - acc: 0.7700 - val_loss: 2.9924 - val_acc: 0.4706\n",
            "Epoch 212/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6023 - acc: 0.7600 - val_loss: 2.7236 - val_acc: 0.4412\n",
            "Epoch 213/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6194 - acc: 0.7400 - val_loss: 2.1687 - val_acc: 0.5882\n",
            "Epoch 214/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7024 - acc: 0.6500 - val_loss: 1.9551 - val_acc: 0.5588\n",
            "Epoch 215/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6251 - acc: 0.7300 - val_loss: 2.7836 - val_acc: 0.4706\n",
            "Epoch 216/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6083 - acc: 0.7500 - val_loss: 2.8651 - val_acc: 0.4706\n",
            "Epoch 217/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5688 - acc: 0.7900 - val_loss: 2.3442 - val_acc: 0.5294\n",
            "Epoch 218/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6039 - acc: 0.7500 - val_loss: 2.4247 - val_acc: 0.5294\n",
            "Epoch 219/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5857 - acc: 0.7700 - val_loss: 2.6322 - val_acc: 0.4706\n",
            "Epoch 220/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5949 - acc: 0.7600 - val_loss: 2.7382 - val_acc: 0.5000\n",
            "Epoch 221/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6307 - acc: 0.7400 - val_loss: 4.7225 - val_acc: 0.4706\n",
            "Epoch 222/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.8488 - acc: 0.7300 - val_loss: 4.8021 - val_acc: 0.4706\n",
            "Epoch 223/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5812 - acc: 0.7600 - val_loss: 4.0862 - val_acc: 0.4706\n",
            "Epoch 224/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7509 - acc: 0.7300 - val_loss: 4.0784 - val_acc: 0.4706\n",
            "Epoch 225/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5861 - acc: 0.7400 - val_loss: 4.0826 - val_acc: 0.4706\n",
            "Epoch 226/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5419 - acc: 0.7800 - val_loss: 4.1136 - val_acc: 0.4706\n",
            "Epoch 227/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6600 - acc: 0.7000 - val_loss: 3.5057 - val_acc: 0.5294\n",
            "Epoch 228/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7448 - acc: 0.7200 - val_loss: 3.1356 - val_acc: 0.4412\n",
            "Epoch 229/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7657 - acc: 0.7300 - val_loss: 2.9609 - val_acc: 0.5000\n",
            "Epoch 230/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6071 - acc: 0.7500 - val_loss: 3.1229 - val_acc: 0.5000\n",
            "Epoch 231/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6039 - acc: 0.7300 - val_loss: 3.1956 - val_acc: 0.5000\n",
            "Epoch 232/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6067 - acc: 0.7400 - val_loss: 3.0929 - val_acc: 0.5000\n",
            "Epoch 233/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6211 - acc: 0.7400 - val_loss: 2.6063 - val_acc: 0.4706\n",
            "Epoch 234/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6298 - acc: 0.7300 - val_loss: 2.6020 - val_acc: 0.5000\n",
            "Epoch 235/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6041 - acc: 0.7500 - val_loss: 2.7241 - val_acc: 0.5294\n",
            "Epoch 236/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6246 - acc: 0.7200 - val_loss: 2.9629 - val_acc: 0.5000\n",
            "Epoch 237/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6213 - acc: 0.7200 - val_loss: 2.3308 - val_acc: 0.5000\n",
            "Epoch 238/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6144 - acc: 0.7600 - val_loss: 2.6008 - val_acc: 0.5000\n",
            "Epoch 239/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6432 - acc: 0.7300 - val_loss: 2.7387 - val_acc: 0.4706\n",
            "Epoch 240/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6399 - acc: 0.7100 - val_loss: 2.7503 - val_acc: 0.4706\n",
            "Epoch 241/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6369 - acc: 0.7400 - val_loss: 4.1268 - val_acc: 0.4706\n",
            "Epoch 242/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6987 - acc: 0.7100 - val_loss: 3.3582 - val_acc: 0.4706\n",
            "Epoch 243/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6052 - acc: 0.7300 - val_loss: 3.3649 - val_acc: 0.4706\n",
            "Epoch 244/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6186 - acc: 0.7300 - val_loss: 3.3406 - val_acc: 0.4706\n",
            "Epoch 245/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6180 - acc: 0.7100 - val_loss: 3.1017 - val_acc: 0.4706\n",
            "Epoch 246/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5772 - acc: 0.7600 - val_loss: 3.1062 - val_acc: 0.4706\n",
            "Epoch 247/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7755 - acc: 0.7400 - val_loss: 3.1414 - val_acc: 0.4118\n",
            "Epoch 248/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6675 - acc: 0.6800 - val_loss: 3.7503 - val_acc: 0.4412\n",
            "Epoch 249/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9376 - acc: 0.6900 - val_loss: 2.9787 - val_acc: 0.5294\n",
            "Epoch 250/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5974 - acc: 0.6900 - val_loss: 3.1622 - val_acc: 0.4412\n",
            "Epoch 251/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7895 - acc: 0.7200 - val_loss: 3.2032 - val_acc: 0.4412\n",
            "Epoch 252/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6952 - acc: 0.7100 - val_loss: 3.3048 - val_acc: 0.4412\n",
            "Epoch 253/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4713 - acc: 0.7100 - val_loss: 3.4564 - val_acc: 0.4412\n",
            "Epoch 254/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9026 - acc: 0.7100 - val_loss: 3.6080 - val_acc: 0.4412\n",
            "Epoch 255/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4932 - acc: 0.6800 - val_loss: 3.6433 - val_acc: 0.4118\n",
            "Epoch 256/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.8139 - acc: 0.6800 - val_loss: 3.8243 - val_acc: 0.4118\n",
            "Epoch 257/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5900 - acc: 0.7400 - val_loss: 3.5948 - val_acc: 0.4118\n",
            "Epoch 258/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6174 - acc: 0.7100 - val_loss: 3.6413 - val_acc: 0.4118\n",
            "Epoch 259/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4482 - acc: 0.7400 - val_loss: 3.2727 - val_acc: 0.4412\n",
            "Epoch 260/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4518 - acc: 0.7500 - val_loss: 3.0102 - val_acc: 0.4412\n",
            "Epoch 261/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6342 - acc: 0.7100 - val_loss: 3.1636 - val_acc: 0.4706\n",
            "Epoch 262/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7719 - acc: 0.7300 - val_loss: 3.2201 - val_acc: 0.4412\n",
            "Epoch 263/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9463 - acc: 0.7000 - val_loss: 3.2457 - val_acc: 0.4412\n",
            "Epoch 264/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6221 - acc: 0.7400 - val_loss: 3.4743 - val_acc: 0.4118\n",
            "Epoch 265/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6420 - acc: 0.7000 - val_loss: 3.4892 - val_acc: 0.4118\n",
            "Epoch 266/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6444 - acc: 0.7000 - val_loss: 3.6367 - val_acc: 0.4118\n",
            "Epoch 267/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7846 - acc: 0.7100 - val_loss: 3.6236 - val_acc: 0.4118\n",
            "Epoch 268/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6287 - acc: 0.7300 - val_loss: 3.4761 - val_acc: 0.4118\n",
            "Epoch 269/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6343 - acc: 0.7900 - val_loss: 4.7025 - val_acc: 0.5000\n",
            "Epoch 270/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4530 - acc: 0.7500 - val_loss: 3.3006 - val_acc: 0.5000\n",
            "Epoch 271/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7432 - acc: 0.7700 - val_loss: 3.9454 - val_acc: 0.4412\n",
            "Epoch 272/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5663 - acc: 0.7800 - val_loss: 4.0346 - val_acc: 0.4412\n",
            "Epoch 273/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7267 - acc: 0.7700 - val_loss: 4.1033 - val_acc: 0.4412\n",
            "Epoch 274/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7205 - acc: 0.7800 - val_loss: 4.1418 - val_acc: 0.4706\n",
            "Epoch 275/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5644 - acc: 0.7800 - val_loss: 4.1631 - val_acc: 0.4706\n",
            "Epoch 276/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6341 - acc: 0.7100 - val_loss: 4.1677 - val_acc: 0.4706\n",
            "Epoch 277/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5839 - acc: 0.7700 - val_loss: 4.1875 - val_acc: 0.4706\n",
            "Epoch 278/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.8864 - acc: 0.7600 - val_loss: 4.1884 - val_acc: 0.4706\n",
            "Epoch 279/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.8953 - acc: 0.7600 - val_loss: 4.2176 - val_acc: 0.4706\n",
            "Epoch 280/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9171 - acc: 0.6100 - val_loss: 3.1073 - val_acc: 0.5882\n",
            "Epoch 281/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.0530 - acc: 0.5600 - val_loss: 2.7603 - val_acc: 0.6176\n",
            "Epoch 282/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5644 - acc: 0.6500 - val_loss: 2.8075 - val_acc: 0.5588\n",
            "Epoch 283/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5858 - acc: 0.7700 - val_loss: 2.9015 - val_acc: 0.5294\n",
            "Epoch 284/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5689 - acc: 0.7800 - val_loss: 3.2231 - val_acc: 0.5294\n",
            "Epoch 285/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5972 - acc: 0.7500 - val_loss: 3.5301 - val_acc: 0.5294\n",
            "Epoch 286/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7578 - acc: 0.7300 - val_loss: 3.2380 - val_acc: 0.5294\n",
            "Epoch 287/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6044 - acc: 0.7300 - val_loss: 3.2329 - val_acc: 0.5294\n",
            "Epoch 288/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5881 - acc: 0.7500 - val_loss: 3.5783 - val_acc: 0.5294\n",
            "Epoch 289/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5909 - acc: 0.7400 - val_loss: 3.6589 - val_acc: 0.5294\n",
            "Epoch 290/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6116 - acc: 0.7400 - val_loss: 3.2804 - val_acc: 0.5294\n",
            "Epoch 291/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5923 - acc: 0.7600 - val_loss: 3.2844 - val_acc: 0.5588\n",
            "Epoch 292/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6551 - acc: 0.7000 - val_loss: 3.0168 - val_acc: 0.5294\n",
            "Epoch 293/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6070 - acc: 0.7300 - val_loss: 3.1092 - val_acc: 0.5294\n",
            "Epoch 294/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7885 - acc: 0.7000 - val_loss: 3.3326 - val_acc: 0.5294\n",
            "Epoch 295/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7505 - acc: 0.7300 - val_loss: 3.4458 - val_acc: 0.5588\n",
            "Epoch 296/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5663 - acc: 0.7700 - val_loss: 3.4532 - val_acc: 0.5588\n",
            "Epoch 297/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6138 - acc: 0.7300 - val_loss: 3.4563 - val_acc: 0.5588\n",
            "Epoch 298/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5565 - acc: 0.7800 - val_loss: 3.4680 - val_acc: 0.5588\n",
            "Epoch 299/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4397 - acc: 0.7500 - val_loss: 3.6402 - val_acc: 0.5588\n",
            "Epoch 300/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5562 - acc: 0.7800 - val_loss: 3.6547 - val_acc: 0.5588\n",
            "Epoch 301/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6237 - acc: 0.7100 - val_loss: 3.6563 - val_acc: 0.5588\n",
            "Epoch 302/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5694 - acc: 0.7600 - val_loss: 3.6516 - val_acc: 0.5588\n",
            "Epoch 303/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5898 - acc: 0.7500 - val_loss: 3.7774 - val_acc: 0.5588\n",
            "Epoch 304/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6101 - acc: 0.7200 - val_loss: 3.8068 - val_acc: 0.5588\n",
            "Epoch 305/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.8877 - acc: 0.7500 - val_loss: 3.8068 - val_acc: 0.5588\n",
            "Epoch 306/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5803 - acc: 0.7500 - val_loss: 3.8095 - val_acc: 0.5588\n",
            "Epoch 307/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5661 - acc: 0.7700 - val_loss: 3.8354 - val_acc: 0.5588\n",
            "Epoch 308/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5556 - acc: 0.7800 - val_loss: 3.8391 - val_acc: 0.5588\n",
            "Epoch 309/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5607 - acc: 0.7700 - val_loss: 3.8434 - val_acc: 0.5588\n",
            "Epoch 310/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5652 - acc: 0.7700 - val_loss: 3.8519 - val_acc: 0.5588\n",
            "Epoch 311/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5905 - acc: 0.7400 - val_loss: 3.8694 - val_acc: 0.5588\n",
            "Epoch 312/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7266 - acc: 0.7600 - val_loss: 3.8915 - val_acc: 0.5588\n",
            "Epoch 313/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5924 - acc: 0.7500 - val_loss: 4.0270 - val_acc: 0.5588\n",
            "Epoch 314/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6149 - acc: 0.7200 - val_loss: 4.0491 - val_acc: 0.5588\n",
            "Epoch 315/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5750 - acc: 0.7600 - val_loss: 4.0643 - val_acc: 0.5588\n",
            "Epoch 316/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5958 - acc: 0.7400 - val_loss: 3.9590 - val_acc: 0.5588\n",
            "Epoch 317/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5477 - acc: 0.7900 - val_loss: 4.0327 - val_acc: 0.5588\n",
            "Epoch 318/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5949 - acc: 0.7400 - val_loss: 4.0361 - val_acc: 0.5588\n",
            "Epoch 319/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6002 - acc: 0.7300 - val_loss: 4.0406 - val_acc: 0.5588\n",
            "Epoch 320/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4437 - acc: 0.7400 - val_loss: 4.0660 - val_acc: 0.5588\n",
            "Epoch 321/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7463 - acc: 0.7400 - val_loss: 4.1121 - val_acc: 0.5588\n",
            "Epoch 322/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5720 - acc: 0.7600 - val_loss: 4.2065 - val_acc: 0.5588\n",
            "Epoch 323/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.0074 - acc: 0.7300 - val_loss: 4.3612 - val_acc: 0.5000\n",
            "Epoch 324/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9247 - acc: 0.7200 - val_loss: 4.2270 - val_acc: 0.5588\n",
            "Epoch 325/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5997 - acc: 0.7300 - val_loss: 4.2309 - val_acc: 0.5588\n",
            "Epoch 326/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6141 - acc: 0.7200 - val_loss: 4.1406 - val_acc: 0.5588\n",
            "Epoch 327/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5753 - acc: 0.7600 - val_loss: 4.1334 - val_acc: 0.5588\n",
            "Epoch 328/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7169 - acc: 0.7700 - val_loss: 4.1452 - val_acc: 0.5588\n",
            "Epoch 329/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5675 - acc: 0.7700 - val_loss: 4.2549 - val_acc: 0.5294\n",
            "Epoch 330/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6701 - acc: 0.7100 - val_loss: 4.2801 - val_acc: 0.5294\n",
            "Epoch 331/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5863 - acc: 0.7500 - val_loss: 4.3520 - val_acc: 0.5000\n",
            "Epoch 332/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7600 - acc: 0.7300 - val_loss: 3.2300 - val_acc: 0.5588\n",
            "Epoch 333/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7545 - acc: 0.7300 - val_loss: 3.6833 - val_acc: 0.5294\n",
            "Epoch 334/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6196 - acc: 0.7100 - val_loss: 3.8268 - val_acc: 0.5294\n",
            "Epoch 335/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5898 - acc: 0.7500 - val_loss: 3.8571 - val_acc: 0.5294\n",
            "Epoch 336/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5227 - acc: 0.8100 - val_loss: 3.9868 - val_acc: 0.5588\n",
            "Epoch 337/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6576 - acc: 0.6800 - val_loss: 3.9798 - val_acc: 0.5588\n",
            "Epoch 338/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4141 - acc: 0.7700 - val_loss: 3.9919 - val_acc: 0.5588\n",
            "Epoch 339/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6050 - acc: 0.7400 - val_loss: 4.1197 - val_acc: 0.5588\n",
            "Epoch 340/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7459 - acc: 0.7500 - val_loss: 4.1213 - val_acc: 0.5588\n",
            "Epoch 341/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5509 - acc: 0.7800 - val_loss: 4.1238 - val_acc: 0.5588\n",
            "Epoch 342/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5957 - acc: 0.7400 - val_loss: 4.1725 - val_acc: 0.5588\n",
            "Epoch 343/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5699 - acc: 0.7700 - val_loss: 4.2271 - val_acc: 0.5294\n",
            "Epoch 344/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5903 - acc: 0.7400 - val_loss: 4.2472 - val_acc: 0.5294\n",
            "Epoch 345/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5699 - acc: 0.7700 - val_loss: 4.2546 - val_acc: 0.5294\n",
            "Epoch 346/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5609 - acc: 0.7700 - val_loss: 4.2643 - val_acc: 0.5588\n",
            "Epoch 347/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6008 - acc: 0.7500 - val_loss: 4.4528 - val_acc: 0.5588\n",
            "Epoch 348/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5959 - acc: 0.7600 - val_loss: 3.8365 - val_acc: 0.5588\n",
            "Epoch 349/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5803 - acc: 0.7500 - val_loss: 3.7774 - val_acc: 0.5588\n",
            "Epoch 350/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5747 - acc: 0.7700 - val_loss: 3.8104 - val_acc: 0.5588\n",
            "Epoch 351/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5596 - acc: 0.7800 - val_loss: 3.8108 - val_acc: 0.5588\n",
            "Epoch 352/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5890 - acc: 0.7600 - val_loss: 3.8119 - val_acc: 0.5588\n",
            "Epoch 353/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5704 - acc: 0.7600 - val_loss: 3.8127 - val_acc: 0.5588\n",
            "Epoch 354/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7716 - acc: 0.7100 - val_loss: 3.8209 - val_acc: 0.5588\n",
            "Epoch 355/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5654 - acc: 0.7700 - val_loss: 3.8412 - val_acc: 0.5882\n",
            "Epoch 356/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6957 - acc: 0.7100 - val_loss: 3.6011 - val_acc: 0.5588\n",
            "Epoch 357/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5651 - acc: 0.7700 - val_loss: 3.6479 - val_acc: 0.5588\n",
            "Epoch 358/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5841 - acc: 0.7600 - val_loss: 3.6734 - val_acc: 0.5294\n",
            "Epoch 359/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7311 - acc: 0.7600 - val_loss: 3.6912 - val_acc: 0.5294\n",
            "Epoch 360/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.3984 - acc: 0.7900 - val_loss: 3.7015 - val_acc: 0.5294\n",
            "Epoch 361/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6090 - acc: 0.7300 - val_loss: 3.2890 - val_acc: 0.5294\n",
            "Epoch 362/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6308 - acc: 0.7100 - val_loss: 3.5259 - val_acc: 0.5588\n",
            "Epoch 363/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7209 - acc: 0.7700 - val_loss: 3.5446 - val_acc: 0.5588\n",
            "Epoch 364/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7554 - acc: 0.7400 - val_loss: 3.5748 - val_acc: 0.5588\n",
            "Epoch 365/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5952 - acc: 0.7400 - val_loss: 3.5985 - val_acc: 0.5588\n",
            "Epoch 366/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.8572 - acc: 0.7100 - val_loss: 2.2377 - val_acc: 0.5882\n",
            "Epoch 367/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6722 - acc: 0.7100 - val_loss: 3.1995 - val_acc: 0.5588\n",
            "Epoch 368/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.8383 - acc: 0.7300 - val_loss: 3.3021 - val_acc: 0.5294\n",
            "Epoch 369/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5896 - acc: 0.7500 - val_loss: 3.8016 - val_acc: 0.5294\n",
            "Epoch 370/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7512 - acc: 0.7200 - val_loss: 3.3824 - val_acc: 0.5294\n",
            "Epoch 371/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4298 - acc: 0.7600 - val_loss: 3.4582 - val_acc: 0.5294\n",
            "Epoch 372/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6040 - acc: 0.7400 - val_loss: 3.4123 - val_acc: 0.5294\n",
            "Epoch 373/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6040 - acc: 0.7400 - val_loss: 3.3940 - val_acc: 0.5294\n",
            "Epoch 374/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6052 - acc: 0.7300 - val_loss: 3.4213 - val_acc: 0.5294\n",
            "Epoch 375/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5947 - acc: 0.7400 - val_loss: 3.4319 - val_acc: 0.5294\n",
            "Epoch 376/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4287 - acc: 0.7500 - val_loss: 3.4325 - val_acc: 0.5294\n",
            "Epoch 377/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.0784 - acc: 0.7100 - val_loss: 3.4424 - val_acc: 0.5294\n",
            "Epoch 378/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9122 - acc: 0.7300 - val_loss: 3.4494 - val_acc: 0.5294\n",
            "Epoch 379/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7927 - acc: 0.7000 - val_loss: 3.5180 - val_acc: 0.5294\n",
            "Epoch 380/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5562 - acc: 0.7800 - val_loss: 3.5344 - val_acc: 0.5294\n",
            "Epoch 381/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5896 - acc: 0.7500 - val_loss: 3.5431 - val_acc: 0.5294\n",
            "Epoch 382/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 1.0359 - acc: 0.7500 - val_loss: 3.5708 - val_acc: 0.5588\n",
            "Epoch 383/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6748 - acc: 0.7400 - val_loss: 3.5544 - val_acc: 0.5588\n",
            "Epoch 384/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.7606 - acc: 0.7300 - val_loss: 3.5522 - val_acc: 0.5588\n",
            "Epoch 385/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.6092 - acc: 0.7300 - val_loss: 3.5544 - val_acc: 0.5588\n",
            "Epoch 386/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5702 - acc: 0.7700 - val_loss: 3.5554 - val_acc: 0.5588\n",
            "Epoch 387/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9213 - acc: 0.7300 - val_loss: 3.5573 - val_acc: 0.5588\n",
            "Epoch 388/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7065 - acc: 0.7800 - val_loss: 3.5666 - val_acc: 0.5588\n",
            "Epoch 389/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7453 - acc: 0.7600 - val_loss: 3.6013 - val_acc: 0.5588\n",
            "Epoch 390/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5996 - acc: 0.7400 - val_loss: 3.6039 - val_acc: 0.5588\n",
            "Epoch 391/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6051 - acc: 0.7300 - val_loss: 3.6316 - val_acc: 0.5588\n",
            "Epoch 392/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6137 - acc: 0.7300 - val_loss: 3.6579 - val_acc: 0.5294\n",
            "Epoch 393/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.5850 - acc: 0.7500 - val_loss: 3.8561 - val_acc: 0.5294\n",
            "Epoch 394/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5850 - acc: 0.7500 - val_loss: 3.8567 - val_acc: 0.5294\n",
            "Epoch 395/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9164 - acc: 0.7300 - val_loss: 3.9928 - val_acc: 0.5294\n",
            "Epoch 396/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9170 - acc: 0.7200 - val_loss: 4.0129 - val_acc: 0.5294\n",
            "Epoch 397/500\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.4269 - acc: 0.7700 - val_loss: 3.9395 - val_acc: 0.5588\n",
            "Epoch 398/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4481 - acc: 0.7400 - val_loss: 3.9395 - val_acc: 0.5588\n",
            "Epoch 399/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5900 - acc: 0.7400 - val_loss: 3.9460 - val_acc: 0.5588\n",
            "Epoch 400/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7590 - acc: 0.7300 - val_loss: 3.9254 - val_acc: 0.5588\n",
            "Epoch 401/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7851 - acc: 0.7000 - val_loss: 3.9234 - val_acc: 0.5588\n",
            "Epoch 402/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5799 - acc: 0.7600 - val_loss: 3.9246 - val_acc: 0.5588\n",
            "Epoch 403/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7035 - acc: 0.7400 - val_loss: 3.7243 - val_acc: 0.5588\n",
            "Epoch 404/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7365 - acc: 0.7500 - val_loss: 3.6573 - val_acc: 0.5588\n",
            "Epoch 405/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.0393 - acc: 0.7500 - val_loss: 3.6802 - val_acc: 0.5588\n",
            "Epoch 406/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7230 - acc: 0.7400 - val_loss: 3.9400 - val_acc: 0.5588\n",
            "Epoch 407/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7657 - acc: 0.7200 - val_loss: 3.9835 - val_acc: 0.5588\n",
            "Epoch 408/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5507 - acc: 0.7800 - val_loss: 3.9915 - val_acc: 0.5588\n",
            "Epoch 409/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6340 - acc: 0.7000 - val_loss: 4.0020 - val_acc: 0.5588\n",
            "Epoch 410/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7789 - acc: 0.7200 - val_loss: 3.9915 - val_acc: 0.5588\n",
            "Epoch 411/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7414 - acc: 0.7400 - val_loss: 4.1827 - val_acc: 0.5882\n",
            "Epoch 412/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5705 - acc: 0.7700 - val_loss: 4.1063 - val_acc: 0.5882\n",
            "Epoch 413/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5895 - acc: 0.7500 - val_loss: 4.1064 - val_acc: 0.5882\n",
            "Epoch 414/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5851 - acc: 0.7500 - val_loss: 4.1198 - val_acc: 0.5882\n",
            "Epoch 415/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7351 - acc: 0.7500 - val_loss: 4.2595 - val_acc: 0.5588\n",
            "Epoch 416/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6803 - acc: 0.7000 - val_loss: 2.9413 - val_acc: 0.5294\n",
            "Epoch 417/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5851 - acc: 0.7500 - val_loss: 4.0575 - val_acc: 0.5588\n",
            "Epoch 418/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4432 - acc: 0.7400 - val_loss: 4.0579 - val_acc: 0.5588\n",
            "Epoch 419/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5801 - acc: 0.7500 - val_loss: 4.0574 - val_acc: 0.5588\n",
            "Epoch 420/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7605 - acc: 0.7300 - val_loss: 4.0577 - val_acc: 0.5588\n",
            "Epoch 421/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5995 - acc: 0.7400 - val_loss: 4.0582 - val_acc: 0.5588\n",
            "Epoch 422/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4238 - acc: 0.7600 - val_loss: 4.0582 - val_acc: 0.5588\n",
            "Epoch 423/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7314 - acc: 0.7600 - val_loss: 4.0584 - val_acc: 0.5588\n",
            "Epoch 424/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9022 - acc: 0.7400 - val_loss: 4.0593 - val_acc: 0.5588\n",
            "Epoch 425/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7267 - acc: 0.7600 - val_loss: 4.0640 - val_acc: 0.5588\n",
            "Epoch 426/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.8578 - acc: 0.7800 - val_loss: 4.0669 - val_acc: 0.5588\n",
            "Epoch 427/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5749 - acc: 0.7600 - val_loss: 4.0669 - val_acc: 0.5588\n",
            "Epoch 428/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7752 - acc: 0.7200 - val_loss: 4.0675 - val_acc: 0.5588\n",
            "Epoch 429/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5770 - acc: 0.7600 - val_loss: 4.0810 - val_acc: 0.5882\n",
            "Epoch 430/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5835 - acc: 0.7600 - val_loss: 4.1028 - val_acc: 0.5588\n",
            "Epoch 431/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5848 - acc: 0.7500 - val_loss: 4.1026 - val_acc: 0.5588\n",
            "Epoch 432/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5608 - acc: 0.7700 - val_loss: 4.1037 - val_acc: 0.5588\n",
            "Epoch 433/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5945 - acc: 0.7500 - val_loss: 4.1092 - val_acc: 0.5588\n",
            "Epoch 434/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6096 - acc: 0.7300 - val_loss: 4.5645 - val_acc: 0.5588\n",
            "Epoch 435/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5740 - acc: 0.7800 - val_loss: 3.8528 - val_acc: 0.5588\n",
            "Epoch 436/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6344 - acc: 0.7000 - val_loss: 3.8397 - val_acc: 0.5588\n",
            "Epoch 437/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5750 - acc: 0.7600 - val_loss: 3.8400 - val_acc: 0.5588\n",
            "Epoch 438/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5783 - acc: 0.7600 - val_loss: 3.9000 - val_acc: 0.5294\n",
            "Epoch 439/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5796 - acc: 0.7600 - val_loss: 3.9014 - val_acc: 0.5294\n",
            "Epoch 440/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5545 - acc: 0.7900 - val_loss: 3.9066 - val_acc: 0.5294\n",
            "Epoch 441/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7316 - acc: 0.7500 - val_loss: 3.9191 - val_acc: 0.5294\n",
            "Epoch 442/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5850 - acc: 0.7500 - val_loss: 3.9209 - val_acc: 0.5294\n",
            "Epoch 443/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5850 - acc: 0.7500 - val_loss: 3.9209 - val_acc: 0.5294\n",
            "Epoch 444/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6094 - acc: 0.7300 - val_loss: 3.9218 - val_acc: 0.5294\n",
            "Epoch 445/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7081 - acc: 0.7800 - val_loss: 3.9271 - val_acc: 0.5294\n",
            "Epoch 446/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6345 - acc: 0.7000 - val_loss: 3.9273 - val_acc: 0.5294\n",
            "Epoch 447/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5506 - acc: 0.7800 - val_loss: 3.9289 - val_acc: 0.5294\n",
            "Epoch 448/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5850 - acc: 0.7500 - val_loss: 3.9990 - val_acc: 0.5294\n",
            "Epoch 449/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6193 - acc: 0.7200 - val_loss: 4.0235 - val_acc: 0.5294\n",
            "Epoch 450/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7656 - acc: 0.7200 - val_loss: 4.0270 - val_acc: 0.5294\n",
            "Epoch 451/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5626 - acc: 0.7700 - val_loss: 4.0923 - val_acc: 0.5294\n",
            "Epoch 452/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.8119 - acc: 0.6800 - val_loss: 2.8813 - val_acc: 0.5294\n",
            "Epoch 453/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5695 - acc: 0.7700 - val_loss: 3.4377 - val_acc: 0.5000\n",
            "Epoch 454/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5657 - acc: 0.7800 - val_loss: 3.4856 - val_acc: 0.5294\n",
            "Epoch 455/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5947 - acc: 0.7400 - val_loss: 3.4877 - val_acc: 0.5294\n",
            "Epoch 456/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5996 - acc: 0.7400 - val_loss: 3.4892 - val_acc: 0.5294\n",
            "Epoch 457/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5727 - acc: 0.7700 - val_loss: 3.5751 - val_acc: 0.5294\n",
            "Epoch 458/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7223 - acc: 0.7600 - val_loss: 3.6007 - val_acc: 0.5294\n",
            "Epoch 459/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5890 - acc: 0.7600 - val_loss: 3.6068 - val_acc: 0.5294\n",
            "Epoch 460/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7415 - acc: 0.7500 - val_loss: 3.7533 - val_acc: 0.5294\n",
            "Epoch 461/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5948 - acc: 0.7400 - val_loss: 3.7610 - val_acc: 0.5294\n",
            "Epoch 462/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5652 - acc: 0.7700 - val_loss: 3.8097 - val_acc: 0.5294\n",
            "Epoch 463/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7756 - acc: 0.7200 - val_loss: 3.8180 - val_acc: 0.5294\n",
            "Epoch 464/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5850 - acc: 0.7500 - val_loss: 3.8264 - val_acc: 0.5294\n",
            "Epoch 465/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5797 - acc: 0.7600 - val_loss: 3.8422 - val_acc: 0.5294\n",
            "Epoch 466/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5638 - acc: 0.7700 - val_loss: 3.9456 - val_acc: 0.5294\n",
            "Epoch 467/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5552 - acc: 0.7800 - val_loss: 3.9470 - val_acc: 0.5294\n",
            "Epoch 468/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7759 - acc: 0.7100 - val_loss: 3.9465 - val_acc: 0.5294\n",
            "Epoch 469/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6047 - acc: 0.7300 - val_loss: 3.9462 - val_acc: 0.5294\n",
            "Epoch 470/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5946 - acc: 0.7400 - val_loss: 3.9472 - val_acc: 0.5294\n",
            "Epoch 471/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5802 - acc: 0.7500 - val_loss: 3.9476 - val_acc: 0.5294\n",
            "Epoch 472/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5942 - acc: 0.7500 - val_loss: 3.9624 - val_acc: 0.5294\n",
            "Epoch 473/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5652 - acc: 0.7700 - val_loss: 4.0509 - val_acc: 0.5294\n",
            "Epoch 474/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6242 - acc: 0.7100 - val_loss: 4.0567 - val_acc: 0.5294\n",
            "Epoch 475/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5798 - acc: 0.7600 - val_loss: 4.0597 - val_acc: 0.5294\n",
            "Epoch 476/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5745 - acc: 0.7700 - val_loss: 4.0617 - val_acc: 0.5294\n",
            "Epoch 477/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.9416 - acc: 0.7000 - val_loss: 4.0629 - val_acc: 0.5294\n",
            "Epoch 478/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5942 - acc: 0.7500 - val_loss: 4.0646 - val_acc: 0.5294\n",
            "Epoch 479/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5897 - acc: 0.7500 - val_loss: 4.0972 - val_acc: 0.5294\n",
            "Epoch 480/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6387 - acc: 0.7000 - val_loss: 4.1049 - val_acc: 0.5294\n",
            "Epoch 481/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7750 - acc: 0.7200 - val_loss: 4.1050 - val_acc: 0.5294\n",
            "Epoch 482/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5801 - acc: 0.7500 - val_loss: 4.1055 - val_acc: 0.5294\n",
            "Epoch 483/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5700 - acc: 0.7700 - val_loss: 4.1266 - val_acc: 0.5294\n",
            "Epoch 484/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5908 - acc: 0.7400 - val_loss: 4.2153 - val_acc: 0.5294\n",
            "Epoch 485/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5750 - acc: 0.7600 - val_loss: 4.2167 - val_acc: 0.5294\n",
            "Epoch 486/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6192 - acc: 0.7200 - val_loss: 4.2162 - val_acc: 0.5294\n",
            "Epoch 487/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5993 - acc: 0.7400 - val_loss: 4.2149 - val_acc: 0.5294\n",
            "Epoch 488/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5649 - acc: 0.7800 - val_loss: 4.2174 - val_acc: 0.5294\n",
            "Epoch 489/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6046 - acc: 0.7300 - val_loss: 4.2169 - val_acc: 0.5294\n",
            "Epoch 490/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5896 - acc: 0.7500 - val_loss: 4.2169 - val_acc: 0.5294\n",
            "Epoch 491/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5661 - acc: 0.7700 - val_loss: 4.2351 - val_acc: 0.5294\n",
            "Epoch 492/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6196 - acc: 0.7700 - val_loss: 3.3599 - val_acc: 0.5294\n",
            "Epoch 493/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.8015 - acc: 0.6800 - val_loss: 3.1694 - val_acc: 0.5294\n",
            "Epoch 494/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.7160 - acc: 0.7700 - val_loss: 3.4617 - val_acc: 0.5294\n",
            "Epoch 495/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5657 - acc: 0.7700 - val_loss: 3.4720 - val_acc: 0.5588\n",
            "Epoch 496/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5799 - acc: 0.7600 - val_loss: 3.5020 - val_acc: 0.5588\n",
            "Epoch 497/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6146 - acc: 0.7200 - val_loss: 3.5023 - val_acc: 0.5588\n",
            "Epoch 498/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5600 - acc: 0.7800 - val_loss: 3.5120 - val_acc: 0.5588\n",
            "Epoch 499/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.5563 - acc: 0.7700 - val_loss: 3.5252 - val_acc: 0.5588\n",
            "Epoch 500/500\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6046 - acc: 0.7300 - val_loss: 3.5347 - val_acc: 0.5588\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_11 (Flatten)         (None, 102400)            0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 10)                1024010   \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 1,024,252\n",
            "Trainable params: 1,024,252\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEgCAYAAACq+TSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEgCAYAAABIJS/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "34/34 [==============================] - 0s 4ms/step\n",
            "Test score: 4.063401645362751\n",
            "Test accuracy: 0.6176470588235294\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}